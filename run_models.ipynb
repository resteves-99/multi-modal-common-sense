{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd09a4d-7b1d-45e8-8fca-5d44cdfefc8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/multi_modal_common_sense/train_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unc-nlp/lxmert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unc-nlp/lxmert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     },\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             resolved_config_file = cached_path(\n\u001b[0m\u001b[1;32m    547\u001b[0m                 \u001b[0mconfig_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1403\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nb/76jp2vmd3yg4dq6tm9mcsddh0000gn/T/ipykernel_21124/2921404536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWrappedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/multi_modal_common_sense/run.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch_processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from run import WrappedModel\n",
    "\n",
    "from collections import defaultdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76175807-888f-4c05-8e14-e36a10a10256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11cdfb7a-3b88-46ed-948a-0c7e829f6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7205563d-d560-4e26-ab28-6c17bf0e104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"clip\": \"openai/clip-vit-base-patch32\",\n",
    "    \"roberta\": \"roberta-base\", \n",
    "    \"roberta_small\": \"klue/roberta-small\", \n",
    "    \"visualbert\": 'uclanlp/visualbert-vqa-coco-pre',\n",
    "    # \"lxmert\": \"unc-nlp/lxmert-base-uncased\", \n",
    "    \"xlnet\": \"xlnet-base-cased\", \n",
    "}\n",
    "\n",
    "attributes = {\"size\": \"bigger\", \"weight\": \"heavier\", \"strength\": \"stronger\", \"rigidness\": \"more rigid\", \"speed\": \"faster\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e2e37da-ec77-4e07-b06f-75646ab7d589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_small-size-pooled=True 66.86094920899251\n",
      "roberta_small-size-pooled=False 79.35054121565362\n",
      "roberta_small-weight-pooled=True 67.58732737611697\n",
      "roberta_small-weight-pooled=False 78.79772542648253\n",
      "roberta_small-strength-pooled=True 66.96832579185521\n",
      "roberta_small-strength-pooled=False 75.38461538461539\n",
      "roberta_small-rigidness-pooled=True 65.85603112840467\n",
      "roberta_small-rigidness-pooled=False 72.66536964980544\n",
      "roberta_small-speed-pooled=True 73.93364928909952\n",
      "roberta_small-speed-pooled=False 79.62085308056872\n"
     ]
    }
   ],
   "source": [
    "# accs = {}\n",
    "\n",
    "for model in MODELS.keys():\n",
    "    for attr in attributes.keys():\n",
    "        for use_pooled in [True, False]:\n",
    "            try:\n",
    "                m = WrappedModel(attributes=attr, model=model, use_pooled=use_pooled)\n",
    "                acc = m.forward()\n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "            name = f\"{model}-{attr}-pooled={use_pooled}\"\n",
    "            accs[name] = acc\n",
    "            print(name, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83149cd9-e652-42b9-bb7c-f02662eec68f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nb/76jp2vmd3yg4dq6tm9mcsddh0000gn/T/ipykernel_59003/36836473.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accs' is not defined"
     ]
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "495290a6-0d73-4250-8c57-6433dc81190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs1 = accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64af9fe8-fa3b-4a52-948d-d7b624aa6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03ee1037-2852-45e3-8f4e-71d36a7173f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=accs.items(), columns=['model', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f9ffa2a-1509-4cc4-b770-e65995726685",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {}\n",
    "for name in accs1:\n",
    "    raw = name.split('-')[0] + \"-\" + name.split('-')[-1]\n",
    "    if raw not in table:\n",
    "        table[raw] = []\n",
    "\n",
    "    table[raw] += [accs1[name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6693f21a-4ae5-4706-aa00-2c90c3753683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[66.36136552872607, 66.28757108042242, 63.16742081447964, 68.28793774319067, 76.18483412322274], [66.94421315570358, 67.26238830219334, 65.88235294117646, 70.03891050583658, 78.90995260663507], [54.53788509575354, 57.27051177904143, 55.65610859728507, 55.54474708171206, 65.04739336492891], [88.17651956702748, 87.40861088545897, 84.34389140271493, 82.87937743190662, 87.79620853080569], [66.86094920899251, 66.28757108042242, 63.07692307692308, 58.268482490272376, 65.63981042654028], [90.17485428809326, 87.40861088545897, 86.42533936651584, 82.1011673151751, 90.04739336492891], [87.59367194004996, 87.08367181153534, 85.3393665158371, 82.29571984435798, 87.91469194312796], [66.86094920899251, 67.58732737611697, 66.96832579185521, 65.85603112840467, 73.93364928909952], [79.35054121565362, 78.79772542648253, 75.38461538461539, 72.66536964980544, 79.62085308056872]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa365acc-6a9d-46a2-9e93-833f5a81dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(index=table.keys(), data=table.values(), columns=['size', 'weight', 'strength', 'rigidness', 'speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "336cd0c5-d682-4810-8b3d-a4f71102a01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>weight</th>\n",
       "      <th>strength</th>\n",
       "      <th>rigidness</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clip-pooled=True</th>\n",
       "      <td>66.361366</td>\n",
       "      <td>66.287571</td>\n",
       "      <td>63.167421</td>\n",
       "      <td>68.287938</td>\n",
       "      <td>76.184834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip-pooled=False</th>\n",
       "      <td>66.944213</td>\n",
       "      <td>67.262388</td>\n",
       "      <td>65.882353</td>\n",
       "      <td>70.038911</td>\n",
       "      <td>78.909953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-pooled=True</th>\n",
       "      <td>54.537885</td>\n",
       "      <td>57.270512</td>\n",
       "      <td>55.656109</td>\n",
       "      <td>55.544747</td>\n",
       "      <td>65.047393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-pooled=False</th>\n",
       "      <td>88.176520</td>\n",
       "      <td>87.408611</td>\n",
       "      <td>84.343891</td>\n",
       "      <td>82.879377</td>\n",
       "      <td>87.796209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visualbert-pooled=True</th>\n",
       "      <td>66.860949</td>\n",
       "      <td>66.287571</td>\n",
       "      <td>63.076923</td>\n",
       "      <td>58.268482</td>\n",
       "      <td>65.639810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visualbert-pooled=False</th>\n",
       "      <td>90.174854</td>\n",
       "      <td>87.408611</td>\n",
       "      <td>86.425339</td>\n",
       "      <td>82.101167</td>\n",
       "      <td>90.047393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-pooled=False</th>\n",
       "      <td>87.593672</td>\n",
       "      <td>87.083672</td>\n",
       "      <td>85.339367</td>\n",
       "      <td>82.295720</td>\n",
       "      <td>87.914692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_small-pooled=True</th>\n",
       "      <td>66.860949</td>\n",
       "      <td>67.587327</td>\n",
       "      <td>66.968326</td>\n",
       "      <td>65.856031</td>\n",
       "      <td>73.933649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_small-pooled=False</th>\n",
       "      <td>79.350541</td>\n",
       "      <td>78.797725</td>\n",
       "      <td>75.384615</td>\n",
       "      <td>72.665370</td>\n",
       "      <td>79.620853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 size     weight   strength  rigidness  \\\n",
       "clip-pooled=True            66.361366  66.287571  63.167421  68.287938   \n",
       "clip-pooled=False           66.944213  67.262388  65.882353  70.038911   \n",
       "roberta-pooled=True         54.537885  57.270512  55.656109  55.544747   \n",
       "roberta-pooled=False        88.176520  87.408611  84.343891  82.879377   \n",
       "visualbert-pooled=True      66.860949  66.287571  63.076923  58.268482   \n",
       "visualbert-pooled=False     90.174854  87.408611  86.425339  82.101167   \n",
       "xlnet-pooled=False          87.593672  87.083672  85.339367  82.295720   \n",
       "roberta_small-pooled=True   66.860949  67.587327  66.968326  65.856031   \n",
       "roberta_small-pooled=False  79.350541  78.797725  75.384615  72.665370   \n",
       "\n",
       "                                speed  \n",
       "clip-pooled=True            76.184834  \n",
       "clip-pooled=False           78.909953  \n",
       "roberta-pooled=True         65.047393  \n",
       "roberta-pooled=False        87.796209  \n",
       "visualbert-pooled=True      65.639810  \n",
       "visualbert-pooled=False     90.047393  \n",
       "xlnet-pooled=False          87.914692  \n",
       "roberta_small-pooled=True   73.933649  \n",
       "roberta_small-pooled=False  79.620853  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e1af38-c86f-4b7f-938e-441edc122fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b8d0d-57c1-4a73-8b94-f2c08f799eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466f753d-493b-4ded-a4dc-34a009f04cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = WrappedModel(attributes='weight', model='clip', use_pooled=True)\n",
    "acc = m.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e25674-d740-413f-b659-a5dfc0d88b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.28757108042242"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30611c48-852d-4b85-ae6d-903344c62a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = WrappedModel(attributes='weight', model='clip', use_pooled=False)\n",
    "acc1 = m.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e3ce20-c0d5-42e8-9b69-7586593aae29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.26238830219334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fb021-b16b-4296-9e07-7288c4dac960",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from run import WrappedModel\n",
    "\n",
    "m = WrappedModel(attributes='weight', model='lxmert', use_pooled=True, verbose=True, batch_size=20)\n",
    "acc1 = m.forward()\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0afe415-8f5c-46a5-8ca3-9b8373cf11e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79888f4e-782b-4a65-a9d5-dc0fb31e10ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'uniter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nb/76jp2vmd3yg4dq6tm9mcsddh0000gn/T/ipykernel_89143/1497329344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWrappedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWrappedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pooled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0macc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macc2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/multi_modal_common_sense/run.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, attributes, model, use_pooled, batch_size, split, dataset_size, verbose, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPTextModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type_to_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'uniter'"
     ]
    }
   ],
   "source": [
    "from run import WrappedModel\n",
    "\n",
    "m = WrappedModel(attributes='weight', model='uniter', use_pooled=False, verbose=False)\n",
    "acc2 = m.forward()\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4acaa-7c41-45e4-9362-31c4b609b38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e06ee321-7c12-476f-86d5-17887a9e1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LxmertModel, AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbb0d66-a2f7-4fe2-a7cd-6b665bb4c803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nb/76jp2vmd3yg4dq6tm9mcsddh0000gn/T/ipykernel_21661/1292416240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;34m\"Hello, my dog is cute\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"boring banana man\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# visual_feats = torch.rand(len(ex), 768, 2048)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "lxmodel = LxmertModel.from_pretrained('unc-nlp/lxmert-base-uncased')\n",
    "lxmert_tokenizer = AutoTokenizer.from_pretrained('unc-nlp/lxmert-base-uncased')\n",
    "ex = [\"Hello, my dog is cute\", \"boring banana man\",\n",
    "     \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "      \"Hello, my dog is cute\", \"boring banana man\",\n",
    "]\n",
    "inputs = tokenizer(ex, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# visual_feats = torch.rand(len(ex), 768, 2048)\n",
    "# bounding_boxes = torch.rand(len(ex), 768, 4)\n",
    "# outputs = model(**inputs, visual_feats=visual_feats, visual_pos=bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10312001-35b2-47df-91c5-7bd23d43057a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e6afe6-e0eb-4e3b-8ab6-74358eb87766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m     \n",
       "\u001b[0mlxmert_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_pair\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPaddingStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtruncation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTruncationStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_token_type_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_overflowing_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_offsets_mapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchEncoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           LxmertTokenizerFast\n",
       "\u001b[0;31mString form:\u001b[0m    PreTrainedTokenizerFast(name_or_path='unc-nlp/lxmert-base-uncased', vocab_size=30522, model_max_l <...> UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
       "\u001b[0;31mLength:\u001b[0m         30522\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/transformers/models/lxmert/tokenization_lxmert_fast.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Construct a \"fast\" LXMERT tokenizer (backed by HuggingFace's `tokenizers` library).\n",
       "\n",
       ":class:`~transformers.LxmertTokenizerFast` is identical to :class:`~transformers.BertTokenizerFast` and runs\n",
       "end-to-end tokenization: punctuation splitting and wordpiece.\n",
       "\n",
       "Refer to superclass :class:`~transformers.BertTokenizerFast` for usage examples and documentation concerning\n",
       "parameters.\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "Main method to tokenize and prepare for the model one or several sequence(s) or one or several pair(s) of\n",
       "sequences.\n",
       "\n",
       "Args:\n",
       "    text (:obj:`str`, :obj:`List[str]`, :obj:`List[List[str]]`):\n",
       "        The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings\n",
       "        (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set\n",
       "        :obj:`is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "    text_pair (:obj:`str`, :obj:`List[str]`, :obj:`List[List[str]]`):\n",
       "        The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings\n",
       "        (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set\n",
       "        :obj:`is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "\n",
       "    add_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
       "        Whether or not to encode the sequences with the special tokens relative to their model.\n",
       "    padding (:obj:`bool`, :obj:`str` or :class:`~transformers.file_utils.PaddingStrategy`, `optional`, defaults to :obj:`False`):\n",
       "        Activates and controls padding. Accepts the following values:\n",
       "\n",
       "        * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a\n",
       "          single sequence if provided).\n",
       "        * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
       "          maximum acceptable input length for the model if that argument is not provided.\n",
       "        * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
       "          different lengths).\n",
       "    truncation (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.TruncationStrategy`, `optional`, defaults to :obj:`False`):\n",
       "        Activates and controls truncation. Accepts the following values:\n",
       "\n",
       "        * :obj:`True` or :obj:`'longest_first'`: Truncate to a maximum length specified with the argument\n",
       "          :obj:`max_length` or to the maximum acceptable input length for the model if that argument is not\n",
       "          provided. This will truncate token by token, removing a token from the longest sequence in the pair\n",
       "          if a pair of sequences (or a batch of pairs) is provided.\n",
       "        * :obj:`'only_first'`: Truncate to a maximum length specified with the argument :obj:`max_length` or to\n",
       "          the maximum acceptable input length for the model if that argument is not provided. This will only\n",
       "          truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
       "        * :obj:`'only_second'`: Truncate to a maximum length specified with the argument :obj:`max_length` or\n",
       "          to the maximum acceptable input length for the model if that argument is not provided. This will only\n",
       "          truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
       "        * :obj:`False` or :obj:`'do_not_truncate'` (default): No truncation (i.e., can output batch with\n",
       "          sequence lengths greater than the model maximum admissible input size).\n",
       "    max_length (:obj:`int`, `optional`):\n",
       "        Controls the maximum length to use by one of the truncation/padding parameters.\n",
       "\n",
       "        If left unset or set to :obj:`None`, this will use the predefined model maximum length if a maximum\n",
       "        length is required by one of the truncation/padding parameters. If the model has no specific maximum\n",
       "        input length (like XLNet) truncation/padding to a maximum length will be deactivated.\n",
       "    stride (:obj:`int`, `optional`, defaults to 0):\n",
       "        If set to a number along with :obj:`max_length`, the overflowing tokens returned when\n",
       "        :obj:`return_overflowing_tokens=True` will contain some tokens from the end of the truncated sequence\n",
       "        returned to provide some overlap between truncated and overflowing sequences. The value of this\n",
       "        argument defines the number of overlapping tokens.\n",
       "    is_split_into_words (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
       "        Whether or not the input is already pre-tokenized (e.g., split into words). If set to :obj:`True`, the\n",
       "        tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)\n",
       "        which it will tokenize. This is useful for NER or token classification.\n",
       "    pad_to_multiple_of (:obj:`int`, `optional`):\n",
       "        If set will pad the sequence to a multiple of the provided value. This is especially useful to enable\n",
       "        the use of Tensor Cores on NVIDIA hardware with compute capability >= 7.5 (Volta).\n",
       "    return_tensors (:obj:`str` or :class:`~transformers.file_utils.TensorType`, `optional`):\n",
       "        If set, will return tensors instead of list of python integers. Acceptable values are:\n",
       "\n",
       "        * :obj:`'tf'`: Return TensorFlow :obj:`tf.constant` objects.\n",
       "        * :obj:`'pt'`: Return PyTorch :obj:`torch.Tensor` objects.\n",
       "        * :obj:`'np'`: Return Numpy :obj:`np.ndarray` objects.\n",
       "\n",
       "    return_token_type_ids (:obj:`bool`, `optional`):\n",
       "        Whether to return token type IDs. If left to the default, will return the token type IDs according to\n",
       "        the specific tokenizer's default, defined by the :obj:`return_outputs` attribute.\n",
       "\n",
       "        `What are token type IDs? <../glossary.html#token-type-ids>`__\n",
       "    return_attention_mask (:obj:`bool`, `optional`):\n",
       "        Whether to return the attention mask. If left to the default, will return the attention mask according\n",
       "        to the specific tokenizer's default, defined by the :obj:`return_outputs` attribute.\n",
       "\n",
       "        `What are attention masks? <../glossary.html#attention-mask>`__\n",
       "    return_overflowing_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
       "        Whether or not to return overflowing token sequences. If a pair of sequences of input ids (or a batch\n",
       "        of pairs) is provided with :obj:`truncation_strategy = longest_first` or :obj:`True`, an error is\n",
       "        raised instead of returning overflowing tokens.\n",
       "    return_special_tokens_mask (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
       "        Whether or not to return special tokens mask information.\n",
       "    return_offsets_mapping (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
       "        Whether or not to return :obj:`(char_start, char_end)` for each token.\n",
       "\n",
       "        This is only available on fast tokenizers inheriting from\n",
       "        :class:`~transformers.PreTrainedTokenizerFast`, if using Python's tokenizer, this method will raise\n",
       "        :obj:`NotImplementedError`.\n",
       "    return_length  (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
       "        Whether or not to return the lengths of the encoded inputs.\n",
       "    verbose (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
       "        Whether or not to print more information and warnings.\n",
       "    **kwargs: passed to the :obj:`self.tokenize()` method\n",
       "\n",
       "Return:\n",
       "    :class:`~transformers.BatchEncoding`: A :class:`~transformers.BatchEncoding` with the following fields:\n",
       "\n",
       "    - **input_ids** -- List of token ids to be fed to a model.\n",
       "\n",
       "      `What are input IDs? <../glossary.html#input-ids>`__\n",
       "\n",
       "    - **token_type_ids** -- List of token type ids to be fed to a model (when :obj:`return_token_type_ids=True`\n",
       "      or if `\"token_type_ids\"` is in :obj:`self.model_input_names`).\n",
       "\n",
       "      `What are token type IDs? <../glossary.html#token-type-ids>`__\n",
       "\n",
       "    - **attention_mask** -- List of indices specifying which tokens should be attended to by the model (when\n",
       "      :obj:`return_attention_mask=True` or if `\"attention_mask\"` is in :obj:`self.model_input_names`).\n",
       "\n",
       "      `What are attention masks? <../glossary.html#attention-mask>`__\n",
       "\n",
       "    - **overflowing_tokens** -- List of overflowing tokens sequences (when a :obj:`max_length` is specified and\n",
       "      :obj:`return_overflowing_tokens=True`).\n",
       "    - **num_truncated_tokens** -- Number of tokens truncated (when a :obj:`max_length` is specified and\n",
       "      :obj:`return_overflowing_tokens=True`).\n",
       "    - **special_tokens_mask** -- List of 0s and 1s, with 1 specifying added special tokens and 0 specifying\n",
       "      regular sequence tokens (when :obj:`add_special_tokens=True` and :obj:`return_special_tokens_mask=True`).\n",
       "    - **length** -- The length of the inputs (when :obj:`return_length=True`)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd14e8-7d3a-4ea3-a772-22cfd56b2301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a1a40-ca80-4628-ad7d-3a00fca9f52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e970ad9-73d1-4bdb-88a6-2da9c6ed803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hugging face -- Easy \n",
    "ex = [\"Your mom is larger than an elephant\"]\n",
    "\n",
    "embed = lxmodel.embeddings.word_embeddings\n",
    "\n",
    "inputs = tokenizer(ex, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "out = embed(inputs['input_ids'])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46512f29-532e-48df-b506-85b994f4c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.uniter.param import args\n",
    "\n",
    "args.batch_size = 18\n",
    "args.epochs = 2\n",
    "args.model = 'uniter'\n",
    "args.load_pretrained = '/models/uniter-base.pt' #load pretrained visualbert model\n",
    "args.max_seq_length = 128 #truncate or pad report lengths to 128 subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eadfc160-4996-4b7f-8e2f-14ece1da8d00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 213450/213450 [00:00<00:00, 824048.39B/s]\n",
      "100%|| 404400730/404400730 [02:26<00:00, 2756495.67B/s]\n"
     ]
    }
   ],
   "source": [
    "from models.uniter.vqa_model import VQAModel\n",
    "\n",
    "# init model\n",
    "model = VQAModel(num_answers = 10, model = args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2221a2b1-3881-44f3-88f1-2b76802c4030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "uniter = model.encoder.model.uniter\n",
    "\n",
    "# Just bert tokenizer, we can use hugging face\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Not Hugging Face -- Also easy?!\n",
    "ex = [\"Your mom is larger than an elephant\"]\n",
    "\n",
    "embed = uniter.embeddings.word_embeddings\n",
    "inputs = tokenizer(ex, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "out = embed(inputs['input_ids'])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc743dc3-61c4-46ba-bb1a-8858f6c77922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062d3aaa-442c-4082-bbea-d97debd7a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_model_v2 import run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bf9f7f-3555-457f-95f3-64308d34f224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [True, False]\n",
    "sentences = [\"a mother is heavier than an elephant\", \"a brain is smaller than a marble\"]\n",
    "\n",
    "test_labels = labels\n",
    "test_sentences = [\"corn is more edible than a hair\", \"cows are more pretty than a house\"]\n",
    "\n",
    "run_model('t5', labels, sentences, test_labels, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a4f8d8-21b4-4376-b3fb-68e639e48a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processor import DoqProcessor, VerbProcessor, ProstProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "244a0319-68f6-43cd-ad97-76b9013b4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['clip', 'visualbert', 't5', 'roberta', 'roberta_small', 'uniter', 'lxmert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a1f101-132c-4ee3-8b0b-3e2097e70df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip\n",
      "Loaded embedding layer: Embedding(49408, 512)\n",
      "Model: clip | Tokenizer: openai/clip-vit-base-patch32\n",
      "Created features from 1100 examples with shape: torch.Size([1100, 9216])\n",
      "Created features from 1100 examples with shape: torch.Size([1100, 9216])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.50      0.56       532\n",
      "           0       0.00      0.00      0.00        39\n",
      "           1       0.58      0.75      0.65       529\n",
      "\n",
      "    accuracy                           0.60      1100\n",
      "   macro avg       0.40      0.41      0.40      1100\n",
      "weighted avg       0.59      0.60      0.58      1100\n",
      "\n",
      "59.90909090909091\n",
      "visualbert\n",
      "Loaded embedding layer: Embedding(30522, 768, padding_idx=1)\n",
      "Model: visual_bert | Tokenizer: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created features from 1100 examples with shape: torch.Size([1100, 12288])\n",
      "Created features from 1100 examples with shape: torch.Size([1100, 12288])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.65      0.66       532\n",
      "           0       0.11      0.03      0.04        39\n",
      "           1       0.65      0.71      0.68       529\n",
      "\n",
      "    accuracy                           0.66      1100\n",
      "   macro avg       0.48      0.46      0.46      1100\n",
      "weighted avg       0.64      0.66      0.65      1100\n",
      "\n",
      "65.63636363636364\n",
      "t5\n",
      "Loaded embedding layer: Embedding(32128, 768)\n",
      "Model: transformer | Tokenizer: t5-base\n",
      "Created features from 1100 examples with shape: torch.Size([1100, 13824])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created features from 1100 examples with shape: torch.Size([1100, 13824])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.64      0.65       532\n",
      "           0       0.05      0.03      0.03        39\n",
      "           1       0.64      0.69      0.66       529\n",
      "\n",
      "    accuracy                           0.64      1100\n",
      "   macro avg       0.45      0.45      0.45      1100\n",
      "weighted avg       0.63      0.64      0.63      1100\n",
      "\n",
      "64.0\n",
      "roberta\n",
      "Loaded embedding layer: Embedding(50265, 768, padding_idx=1)\n",
      "Model: roberta | Tokenizer: roberta-base\n",
      "Created features from 1100 examples with shape: torch.Size([1100, 13056])\n",
      "Created features from 1100 examples with shape: torch.Size([1100, 12288])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 12288 features, but LogisticRegression is expecting 13056 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nb/76jp2vmd3yg4dq6tm9mcsddh0000gn/T/ipykernel_21124/2524946564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/multi_modal_common_sense/run_model_v2.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model_name, labels, sentences, test_labels, test_sentences, verbose)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/multi_modal_common_sense/run_model_v2.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(lr, test_features, test_labels, return_probs, verbose)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# print(f\"Testing on [{len(test_labels)}] samples\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 12288 features, but LogisticRegression is expecting 13056 features as input."
     ]
    }
   ],
   "source": [
    "doq_train = DoqProcessor('train')\n",
    "train_labels, _, train_sentences, _ = doq_train.forward()\n",
    "\n",
    "doq_test = DoqProcessor('test')\n",
    "test_labels, _, test_sentences, _ = doq_test.forward()\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    acc = run_model(model, train_labels, train_sentences, test_labels, test_sentences, verbose=True)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "299baf93-4aab-4c0c-92c2-4b9077dd8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = defaultdict(int)\n",
    "\n",
    "for c in train_sentences:\n",
    "    counts[len(c.split())] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8ba154-2532-4601-a435-c0902b85391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400f631-3670-4a50-b18c-249ba5fe0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prost_train = ProstProcessor('train')\n",
    "train_labels, _, train_sentences, _ = prost_train.forward()\n",
    "\n",
    "prost_test = ProstProcessor('test')\n",
    "test_labels, _, test_sentences, _ = prost_test.forward()\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    acc = run_model(model, train_labels, train_sentences, test_labels, test_sentences, verbose=True)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fd1c0a-2bf9-4148-a7a4-37d429e4b7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip\n",
      "Loaded embedding layer: Embedding(49408, 512)\n",
      "Model: clip | Tokenizer: openai/clip-vit-base-patch32\n",
      "Created features from 518 examples with shape: torch.Size([518, 512])\n",
      "Created features from 1289 examples with shape: torch.Size([1289, 512])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       526\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.55      1.00      0.71       705\n",
      "\n",
      "    accuracy                           0.55      1289\n",
      "   macro avg       0.18      0.33      0.24      1289\n",
      "weighted avg       0.30      0.55      0.39      1289\n",
      "\n",
      "54.69356089992242\n",
      "visualbert\n",
      "Loaded embedding layer: Embedding(30522, 768, padding_idx=1)\n",
      "Model: visual_bert | Tokenizer: bert-base-uncased\n",
      "Created features from 518 examples with shape: torch.Size([518, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created features from 1289 examples with shape: torch.Size([1289, 768])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       526\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.55      1.00      0.71       705\n",
      "\n",
      "    accuracy                           0.55      1289\n",
      "   macro avg       0.18      0.33      0.24      1289\n",
      "weighted avg       0.30      0.55      0.39      1289\n",
      "\n",
      "54.69356089992242\n",
      "t5\n",
      "Loaded embedding layer: Embedding(32128, 768)\n",
      "Model: transformer | Tokenizer: t5-base\n",
      "Created features from 518 examples with shape: torch.Size([518, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created features from 1289 examples with shape: torch.Size([1289, 768])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.65      0.61       526\n",
      "           0       0.25      0.50      0.33        58\n",
      "           1       0.69      0.56      0.62       705\n",
      "\n",
      "    accuracy                           0.60      1289\n",
      "   macro avg       0.50      0.57      0.52      1289\n",
      "weighted avg       0.62      0.60      0.60      1289\n",
      "\n",
      "59.50349107835532\n",
      "roberta\n",
      "Loaded embedding layer: Embedding(50265, 768, padding_idx=1)\n",
      "Model: roberta | Tokenizer: roberta-base\n",
      "Created features from 518 examples with shape: torch.Size([518, 768])\n",
      "Created features from 1289 examples with shape: torch.Size([1289, 768])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.34      0.46       526\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.61      0.89      0.72       705\n",
      "\n",
      "    accuracy                           0.63      1289\n",
      "   macro avg       0.43      0.41      0.39      1289\n",
      "weighted avg       0.61      0.63      0.58      1289\n",
      "\n",
      "62.606671838634604\n",
      "roberta_small\n",
      "Loaded embedding layer: Embedding(32000, 768, padding_idx=1)\n",
      "Model: roberta | Tokenizer: klue/roberta-small\n",
      "Created features from 518 examples with shape: torch.Size([518, 768])\n",
      "Created features from 1289 examples with shape: torch.Size([1289, 768])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       526\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.55      1.00      0.71       705\n",
      "\n",
      "    accuracy                           0.55      1289\n",
      "   macro avg       0.18      0.33      0.24      1289\n",
      "weighted avg       0.30      0.55      0.39      1289\n",
      "\n",
      "54.69356089992242\n",
      "uniter\n",
      "Loaded embedding layer: Embedding(28996, 768, padding_idx=0)\n",
      "Model: uniter | Tokenizer: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created features from 518 examples with shape: torch.Size([518, 768])\n",
      "Created features from 1289 examples with shape: torch.Size([1289, 768])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       526\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.55      1.00      0.71       705\n",
      "\n",
      "    accuracy                           0.55      1289\n",
      "   macro avg       0.18      0.33      0.24      1289\n",
      "weighted avg       0.30      0.55      0.39      1289\n",
      "\n",
      "54.69356089992242\n",
      "lxmert\n",
      "Loaded embedding layer: Embedding(30522, 768, padding_idx=0)\n",
      "Model: lxmert | Tokenizer: unc-nlp/lxmert-base-uncased\n",
      "Created features from 518 examples with shape: torch.Size([518, 768])\n",
      "Created features from 1289 examples with shape: torch.Size([1289, 768])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       526\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.55      1.00      0.71       705\n",
      "\n",
      "    accuracy                           0.55      1289\n",
      "   macro avg       0.18      0.33      0.24      1289\n",
      "weighted avg       0.30      0.55      0.39      1289\n",
      "\n",
      "54.69356089992242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/g/Desktop/ClassesFall21/cs197/.env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "verb_train = VerbProcessor('weight', 20, 'train', 0)\n",
    "train_labels, _, train_sentences, _ = verb_train.forward()\n",
    "\n",
    "verb_test = VerbProcessor('weight', 20, 'test', 0)\n",
    "test_labels, _, test_sentences, _ = verb_test.forward()\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    acc = run_model(model, train_labels, train_sentences, test_labels, test_sentences, verbose=True)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0fde94a-f34c-4794-ae48-f7b258c2031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_train = defaultdict(int)\n",
    "\n",
    "for c in train_sentences:\n",
    "    counts_train[len(c.split())] += 1\n",
    "\n",
    "counts_test = defaultdict(int)\n",
    "\n",
    "for c in test_sentences:\n",
    "    counts_test[len(c.split())] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db61002a-7a70-48cc-9b1c-911e9a3912d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {7: 518})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dab0ff1f-f667-4e66-a15c-affdf4eaf1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {7: 1289})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec0a9e5-3170-4569-9ef5-55c9c01b2155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([518, 15, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from run_model_v2 import WordModel\n",
    "\n",
    "m = WordModel('clip')\n",
    "features = m.get_features(train_sentences)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e4d639-bcd9-4ca9-b1a5-3bb20836f916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([518, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f36f09-9776-42dc-8ea2-a6ebf9e40a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
